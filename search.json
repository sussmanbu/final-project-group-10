[
  {
    "objectID": "posts/2023-10-15-getting-started/getting-started.html",
    "href": "posts/2023-10-15-getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Below, the items marked with [[OP]] should only be done by one person on the team.\n\nTo get started\n\n[[OP]] One person from the team should click the Github Classroom link on Teams.\n[[OP]] That person types in the group name for their group.\nThe rest of the team now clicks the Github Classroom link and selects their team from the dropdown list.\nFinally, each of you can clone the repository to your laptop like a normal assignment.\n\n\n\nSetting up the site\n\n[[OP]] Open the terminal and run quarto publish gh-pages.\n[[OP]] Select Yes to the prompt:  ? Publish site to https://sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME/ using gh-pages? (Y/n)\n[[OP]] Wait for the process to finish.\nOnce it is done, you can go to the URL it asked you about to see your site.\n\nNote: This is the process you will use every time you want to update your published site. Make sure to always follow the steps below for rendering, previewing, and committing your changes before doing these publish steps. Anyone can publish in the future.\n\n\nCustomize your site\n\n[[OP]] Open the _quarto.yml file and update the title to include your team name.\n[[OP]] Go to the about.qmd and remove the TF’s and professor’s names.\nadd your own along with a short introduction and a link to your Github user page.\n[[OP]] Render the site.\n[[OP]] Check and make sure you didn’t get any errors.\n[[OP]] Commit your changes and push.\n[[OP]] Repeat the steps under Setting up your site.\n\nOnce one person is done with this, each teammate in the group can, in turn, repeat steps 3-7. Before doing so, make sure to pull the changes from teammates before starting to make new changes. (We’ll talk soon about ways to organize your work and resolve conflicts.)\n\n\nStart your first post\n\nTo start your first post first, run remotes::install_github(\"sussmanbu/quartopost\") in your Console.\n[[OP]] Run quartopost::quartopost() (or click Addins-&gt;Create Quarto Post, or use C-Shift-P, type “Create Quarto” and press enter to run the command).\n\nNow you can start working on your post. You’ll want to render your post to see what it will look like on the site.\n\nEvery time you want to make a new post, you can repeat step 2 above.\nWhen you want to publish your progress, follow steps 4-7 from Customize your site.\n\nFinally, make sure to read through everything on this site which has the directions and rubric for the final project."
  },
  {
    "objectID": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "href": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "title": "First Team Meeting",
    "section": "",
    "text": "These are the steps that you will take today to get started on your project. Today, you will just be brainstorming, and then next week, you’ll get started on the main aspects of the project.\n\nStart by introducing yourselves to each other. I also recommend creating a private channel on Microsoft Teams with all your team members. This will be a place that you can communicate and share ideas, code, problems, etc.\nDiscuss what aspects of the project each of you are more or less excited about. These include\n\nCollecting, cleaning, and munging data ,\nStatistical Modeling,\nVisualization,\nWriting about analyses, and\nManaging and reviewing team work.\n\nBased on this, discuss where you feel your strengths and weaknesses might be.\nNext, start brainstorming questions you hope to answer as part of this project. This question should in some way be addressing issues around racial disparities. The questions you come up with should be at the level of the question we started with when exploring the HMDA data. (“Are there differences in the ease of securing a loan based on the race of the applicant?”) You’ll revise your questions a lot over the course of the project. Come up with a few questions that your group might be interested in exploring.\nBased on these questions, start looking around for data that might help you analyze this. If you are looking at U.S. based data, data.gov is a good source and if you are looking internationally, I recommend checking out the World Bank. Also, try Googling for data. Include “data set” or “dataset” in your query. You might even include “CSV” or some other format. Using “data” by itself in your query often doesn’t work too well. Spend some time searching for data and try to come up with at least three possible data sets. (For your first blog post, you’ll write short proposals about each of them that I’ll give feedback on.)\nCome up with a team name. Next week, I’ll provide the Github Classroom assignment that will be where you work on your final project and you’ll have to have your team name finalized by then. Your project will be hosted online at the website with a URL like sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME.\n\nNext time, you’ll get your final project website set up and write your first blog post."
  },
  {
    "objectID": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html",
    "href": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html",
    "title": "Blog post 4: Exploring the Data",
    "section": "",
    "text": "As seen in blog post 3, race was a predictor variable in the scores seen in students. Economic status is another. We want to see how these two variables work together, rather than individually like we did last week."
  },
  {
    "objectID": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html#our-trends",
    "href": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html#our-trends",
    "title": "Blog post 4: Exploring the Data",
    "section": "",
    "text": "As seen in blog post 3, race was a predictor variable in the scores seen in students. Economic status is another. We want to see how these two variables work together, rather than individually like we did last week."
  },
  {
    "objectID": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html#more-exploration",
    "href": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html#more-exploration",
    "title": "Blog post 4: Exploring the Data",
    "section": "More Exploration",
    "text": "More Exploration\nOur regression model predicts the average test score (mn_score_all) based on subgroup-specific test scores, including those for Asian (mn_score_asn), Black (mn_score_blk), economically challenged (mn_score_ecd), female (mn_score_fem), Hispanic (mn_score_hsp), male (mn_score_male), multiracial (mn_score_mtr), and white (mn_score_wht) students. Each coefficient (β) represents the expected change in the average test score for a one-unit change in the corresponding subgroup’s test score. We anticipate identifying significant associations between subgroup-specific performance and the overall average test score. Our model’s goodness of fit will be evaluated using metrics such as R-squared and the F-statistic’s significance, while residual plots will ensure adherence to model assumptions."
  },
  {
    "objectID": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html#linear-regression-model",
    "href": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html#linear-regression-model",
    "title": "Blog post 4: Exploring the Data",
    "section": "Linear regression model",
    "text": "Linear regression model\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nCall:\nlm(formula = mn_score_all ~ mn_score_asn + mn_score_blk + mn_score_ecd + \n    mn_score_fem + mn_score_hsp + mn_score_male + mn_score_mtr + \n    mn_score_wht, data = cleaned_seda)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.149243 -0.001161  0.000157  0.001379  0.116629 \n\nCoefficients:\n                Estimate Std. Error  t value Pr(&gt;|t|)    \n(Intercept)   -0.0006510  0.0002197   -2.963  0.00306 ** \nmn_score_asn   0.0002542  0.0001933    1.315  0.18852    \nmn_score_blk   0.0004158  0.0004016    1.035  0.30058    \nmn_score_ecd  -0.0008749  0.0006534   -1.339  0.18058    \nmn_score_fem   0.4919088  0.0005186  948.496  &lt; 2e-16 ***\nmn_score_hsp  -0.0003652  0.0004426   -0.825  0.40926    \nmn_score_male  0.5055422  0.0004796 1054.161  &lt; 2e-16 ***\nmn_score_mtr  -0.0001177  0.0003305   -0.356  0.72171    \nmn_score_wht   0.0010162  0.0003667    2.771  0.00559 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.006255 on 11423 degrees of freedom\n  (220146 observations deleted due to missingness)\nMultiple R-squared:  0.9997,    Adjusted R-squared:  0.9997 \nF-statistic: 4.84e+06 on 8 and 11423 DF,  p-value: &lt; 2.2e-16\n\n\nThe summary output of the regression model demonstrates an exceptional fit to the data, with a remarkably low residual standard error of 0.006255, indicating minimal unexplained variability in the dependent variable. The multiple R-squared value of 0.9997 suggests that nearly all of the variance in the dependent variable is accounted for by the independent variables included in the model, while the adjusted R-squared value confirms this finding, adjusting for the number of predictors. The F-statistic is impressively large at 4.84e+06, with an associated p-value of less than 2.2e-16, providing strong evidence of the model’s overall significance. However, it’s noteworthy that not all coefficient estimates are statistically significant at the 5% level, suggesting that while the model as a whole is highly significant, individual predictors may not contribute significantly to explaining the variability in the dependent variable. Despite this, the model still offers valuable insights into the relationship between subgroup-specific test scores and overall average test performance."
  },
  {
    "objectID": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html#residuals-and-related-statistics-table",
    "href": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html#residuals-and-related-statistics-table",
    "title": "Blog post 4: Exploring the Data",
    "section": "Residuals and Related Statistics Table:",
    "text": "Residuals and Related Statistics Table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.rownames\nmn_score_all\nmn_score_asn\nmn_score_blk\nmn_score_ecd\nmn_score_fem\nmn_score_hsp\nmn_score_male\nmn_score_mtr\nmn_score_wht\n.fitted\n.resid\n.hat\n.sigma\n.cooksd\n.std.resid\n\n\n\n\n107\n0.1134292\n0.9829746\n-0.2983284\n-0.3294385\n0.1148855\n-0.3626843\n0.1136410\n0.2805765\n0.0495640\n0.1138764\n-0.0004472\n0.0008911\n0.0062549\n0.0000005\n-0.0715364\n\n\n108\n0.0760754\n0.7291931\n-0.2113104\n-0.3534027\n0.1631109\n-0.3716772\n-0.0106456\n0.3620487\n0.1882159\n0.0748940\n0.0011814\n0.0005812\n0.0062549\n0.0000023\n0.1889416\n\n\n109\n0.1112676\n0.9153073\n-0.2558291\n-0.3115971\n0.1165555\n-0.3414314\n0.1079094\n0.2338559\n0.1268593\n0.1118614\n-0.0005938\n0.0006353\n0.0062549\n0.0000006\n-0.0949690\n\n\n110\n0.1713191\n0.7911062\n-0.1383624\n-0.2519623\n0.2570116\n-0.2600592\n0.0839315\n0.4764108\n0.2867727\n0.1689005\n0.0024186\n0.0005101\n0.0062548\n0.0000085\n0.3867932\n\n\n111\n0.2622078\n0.8875326\n-0.0974942\n-0.1784335\n0.4118255\n-0.1631456\n0.0996092\n0.5844247\n0.3390900\n0.2529628\n0.0092450\n0.0006936\n0.0062543\n0.0001686\n1.4786191\n\n\n112\n0.1454739\n0.8836713\n-0.2634955\n-0.3270029\n0.1728129\n-0.3292740\n0.1140409\n0.3294725\n0.1872683\n0.1426826\n0.0027913\n0.0005490\n0.0062548\n0.0000122\n0.4464006"
  },
  {
    "objectID": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html#residual-plot",
    "href": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html#residual-plot",
    "title": "Blog post 4: Exploring the Data",
    "section": "Residual Plot",
    "text": "Residual Plot\n\n\n\n\n\nThe Residuals vs. Fitted plot signals an excellent fit of the regression model to the data. This close alignment indicates minimal discrepancies between predicted and observed values, while the consistent spread of residuals suggests uniform variability across different levels of the independent variables. With no discernible patterns, the model accurately captures underlying relationships without systematic errors, meeting key assumptions of linear regression. However, it’s worth noting the presence of some visible leverage points in the data."
  },
  {
    "objectID": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html#summary-tables",
    "href": "posts/2024-04-08-blog-4-exploring-the-data/blog-4-exploring-the-data.html#summary-tables",
    "title": "Blog post 4: Exploring the Data",
    "section": "Summary Tables",
    "text": "Summary Tables\n\n\n   district              year         state             subject         \n Length:231578      Min.   :2009   Length:231578      Length:231578     \n Class :character   1st Qu.:2011   Class :character   Class :character  \n Mode  :character   Median :2013   Mode  :character   Mode  :character  \n                    Mean   :2013                                        \n                    3rd Qu.:2016                                        \n                    Max.   :2018                                        \n                                                                        \n  mn_score_all      numstu_all       mn_score_asn      numstu_asn      \n Min.   :-3.735   Min.   :    1.0   Min.   :-2.92    Min.   :    1.00  \n 1st Qu.:-0.198   1st Qu.:   35.0   1st Qu.: 0.26    1st Qu.:    2.00  \n Median : 0.030   Median :   92.5   Median : 0.60    Median :    3.83  \n Mean   : 0.025   Mean   :  290.5   Mean   : 0.59    Mean   :   29.22  \n 3rd Qu.: 0.249   3rd Qu.:  237.5   3rd Qu.: 0.93    3rd Qu.:   14.00  \n Max.   : 2.865   Max.   :74519.0   Max.   : 2.79    Max.   :11901.33  \n NA's   :23209    NA's   :14        NA's   :204226   NA's   :119983    \n  mn_score_blk      numstu_blk        mn_score_ecd     numstu_ecd      \n Min.   :-3.40    Min.   :    1.00   Min.   :-3.55   Min.   :    1.00  \n 1st Qu.:-0.63    1st Qu.:    2.25   1st Qu.:-0.42   1st Qu.:   15.00  \n Median :-0.45    Median :    6.25   Median :-0.24   Median :   38.33  \n Mean   :-0.44    Mean   :   76.19   Mean   :-0.26   Mean   :  157.82  \n 3rd Qu.:-0.25    3rd Qu.:   35.33   3rd Qu.:-0.08   3rd Qu.:  105.17  \n Max.   : 1.16    Max.   :21703.67   Max.   : 1.24   Max.   :61479.33  \n NA's   :180011   NA's   :92324      NA's   :61878   NA's   :5933      \n  mn_score_fem     numstu_fem        mn_score_hsp      numstu_hsp      \n Min.   :-2.33   Min.   :    1.00   Min.   :-2.36    Min.   :    1.00  \n 1st Qu.:-0.13   1st Qu.:   17.50   1st Qu.:-0.47    1st Qu.:    2.67  \n Median : 0.10   Median :   45.67   Median :-0.28    Median :    7.20  \n Mean   : 0.10   Mean   :  142.82   Mean   :-0.27    Mean   :   87.50  \n 3rd Qu.: 0.32   3rd Qu.:  116.67   3rd Qu.:-0.07    3rd Qu.:   31.00  \n Max.   : 1.99   Max.   :36852.67   Max.   : 1.29    Max.   :38164.75  \n NA's   :51590   NA's   :2566       NA's   :163129   NA's   :45649     \n mn_score_male    numstu_male        mn_score_mtr      numstu_mtr     \n Min.   :-3.63   Min.   :    1.00   Min.   :-1.99    Min.   :   1.00  \n 1st Qu.:-0.26   1st Qu.:   18.33   1st Qu.:-0.17    1st Qu.:   2.00  \n Median :-0.03   Median :   47.83   Median : 0.05    Median :   4.00  \n Mean   :-0.03   Mean   :  149.41   Mean   : 0.08    Mean   :  13.04  \n 3rd Qu.: 0.21   3rd Qu.:  122.50   3rd Qu.: 0.30    3rd Qu.:  10.17  \n Max.   : 1.88   Max.   :37666.33   Max.   : 1.75    Max.   :1904.00  \n NA's   :49363   NA's   :2008       NA's   :207528   NA's   :107040   \n   numstu_nec        mn_score_wht     numstu_wht          pernam        \n Min.   :    1.00   Min.   :-1.96   Min.   :    1.0   Min.   :0.000000  \n 1st Qu.:   16.33   1st Qu.:-0.05   1st Qu.:   23.2   1st Qu.:0.000000  \n Median :   45.67   Median : 0.14   Median :   64.0   Median :0.002287  \n Mean   :  140.00   Mean   : 0.15   Mean   :  147.5   Mean   :0.030611  \n 3rd Qu.:  123.17   3rd Qu.: 0.35   3rd Qu.:  155.7   3rd Qu.:0.007715  \n Max.   :19079.33   Max.   : 1.88   Max.   :11594.3   Max.   :1.000000  \n NA's   :10745      NA's   :42345   NA's   :3927                        \n     perasn              perhsp            perblk             perwht      \n Min.   :0.0000000   Min.   :0.00000   Min.   :0.000000   Min.   :0.0000  \n 1st Qu.:0.0003241   1st Qu.:0.01727   1st Qu.:0.004082   1st Qu.:0.5935  \n Median :0.0060004   Median :0.04780   Median :0.014202   Median :0.8551  \n Mean   :0.0200166   Mean   :0.13648   Mean   :0.076236   Mean   :0.7367  \n 3rd Qu.:0.0169583   3rd Qu.:0.15038   3rd Qu.:0.052917   3rd Qu.:0.9492  \n Max.   :1.0000000   Max.   :1.00000   Max.   :1.000000   Max.   :1.0000  \n                                                                          \n     perfl              perecd          perell          perspeced     \n Min.   :0.001393   Min.   :0.003   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.246492   1st Qu.:0.344   1st Qu.:0.00000   1st Qu.:0.1083  \n Median :0.387229   Median :0.500   Median :0.00922   Median :0.1356  \n Mean   :0.405621   Mean   :0.502   Mean   :0.04227   Mean   :0.1381  \n 3rd Qu.:0.545455   3rd Qu.:0.654   3rd Qu.:0.04190   3rd Qu.:0.1655  \n Max.   :0.994910   Max.   :1.000   Max.   :1.00000   Max.   :1.2639  \n                    NA's   :3246    NA's   :168       NA's   :168     \n    totenrl            unempall        snapall      single_momall  \n Min.   :    0.80   Min.   :0.000   Min.   :0.000   Min.   :0.002  \n 1st Qu.:   35.50   1st Qu.:0.054   1st Qu.:0.057   1st Qu.:0.109  \n Median :   93.33   Median :0.070   Median :0.096   Median :0.142  \n Mean   :  294.20   Mean   :0.072   Mean   :0.105   Mean   :0.151  \n 3rd Qu.:  240.50   3rd Qu.:0.087   3rd Qu.:0.142   3rd Qu.:0.181  \n Max.   :74619.83   Max.   :0.357   Max.   :0.524   Max.   :0.615  \n                    NA's   :6235    NA's   :6235    NA's   :6235"
  },
  {
    "objectID": "posts/2024-04-01-blog-post-3-equity-and-data-cleaning/blog-post-3-equity-and-data-cleaning.html",
    "href": "posts/2024-04-01-blog-post-3-equity-and-data-cleaning/blog-post-3-equity-and-data-cleaning.html",
    "title": "Blog Post 3: Equity and Data Cleaning",
    "section": "",
    "text": "We cleaned our data before importing, as it was 500mB. We kept the scores for each race and the locations, as that is what we are most interested in."
  },
  {
    "objectID": "posts/2024-04-01-blog-post-3-equity-and-data-cleaning/blog-post-3-equity-and-data-cleaning.html#our-data",
    "href": "posts/2024-04-01-blog-post-3-equity-and-data-cleaning/blog-post-3-equity-and-data-cleaning.html#our-data",
    "title": "Blog Post 3: Equity and Data Cleaning",
    "section": "",
    "text": "We cleaned our data before importing, as it was 500mB. We kept the scores for each race and the locations, as that is what we are most interested in."
  },
  {
    "objectID": "posts/2024-04-01-blog-post-3-equity-and-data-cleaning/blog-post-3-equity-and-data-cleaning.html#preliminary-tables",
    "href": "posts/2024-04-01-blog-post-3-equity-and-data-cleaning/blog-post-3-equity-and-data-cleaning.html#preliminary-tables",
    "title": "Blog Post 3: Equity and Data Cleaning",
    "section": "Preliminary Tables",
    "text": "Preliminary Tables\nTo begin, we wanted to make a summary table of general descriptibe statistics for the races included in our data as well as the economically challenged students to see the variation between their test scores. This is not broken down by location yet but we wanted to better visualize the data so we would know how to proceed.\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n  mn_score_all     mn_score_asn     mn_score_blk     mn_score_ecd  \n Min.   :-3.735   Min.   :-2.92    Min.   :-3.40    Min.   :-3.55  \n 1st Qu.:-0.197   1st Qu.: 0.26    1st Qu.:-0.63    1st Qu.:-0.42  \n Median : 0.030   Median : 0.60    Median :-0.45    Median :-0.24  \n Mean   : 0.025   Mean   : 0.59    Mean   :-0.44    Mean   :-0.26  \n 3rd Qu.: 0.249   3rd Qu.: 0.93    3rd Qu.:-0.25    3rd Qu.:-0.08  \n Max.   : 2.865   Max.   : 2.79    Max.   : 1.16    Max.   : 1.24  \n NA's   :23236    NA's   :205143   NA's   :180838   NA's   :61961"
  },
  {
    "objectID": "posts/2024-04-01-blog-post-3-equity-and-data-cleaning/blog-post-3-equity-and-data-cleaning.html#plots",
    "href": "posts/2024-04-01-blog-post-3-equity-and-data-cleaning/blog-post-3-equity-and-data-cleaning.html#plots",
    "title": "Blog Post 3: Equity and Data Cleaning",
    "section": "Plots",
    "text": "Plots\nOur next step for Data Cleaning process is to analyze the histograms for selected variables.By examining these histograms, we can visually analyze the distribution of test scores within each subgroup. This visualization helps in understanding the spread, central tendency, and potential outliers within the test scores across different racial groups and economic statuses.\n\n\n\n\n\nAdditionally, we need to look at the boxplots of selected variables for the Data Cleaning process. The boxplots of test scores across racial and economic groups reveal outliers, differences in central tendency and spread, skewness or symmetry, disparities between groups, and missing values. These observations guide data cleaning efforts to ensure the reliability of subsequent analyses.\n\n\nWarning: Removed 471178 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "posts/2024-04-01-blog-post-3-equity-and-data-cleaning/blog-post-3-equity-and-data-cleaning.html#data-equity",
    "href": "posts/2024-04-01-blog-post-3-equity-and-data-cleaning/blog-post-3-equity-and-data-cleaning.html#data-equity",
    "title": "Blog Post 3: Equity and Data Cleaning",
    "section": "Data Equity",
    "text": "Data Equity\nThe Stanford Education Data Archive (SEDA) presents an opportunity to use educational data to benefit all students, especially those from underprivileged communities. Researchers and policymakers can use SEDA as a helpful tool for social justice in education by upholding the principles of beneficence and justice.\nIt’s important to prioritize research addressing educational disparities. Our research involves conducting analyses highlighting gaps and identifying actional resource allocation. By focusing on the needs of underserved communities, such research can lead to policy recommendations that impact students’ educational experiences and outcomes. Researchers must prioritize analyses that offer tangible solutions to underserved communities, ensuring that the insights gained do not disproportionately benefit advantaged groups.\nWe need to ensure that research findings are accessible to a wide range of stakeholders, including educators, policymakers, and community members, to enable informed decision-making across all levels of the education system. Restricting access to sensitive information protects the privacy and security of individuals represented in the data."
  },
  {
    "objectID": "posts/2024-03-04-blog-post-1-possible-data-sets/blog-post-1-possible-data-sets.html",
    "href": "posts/2024-03-04-blog-post-1-possible-data-sets/blog-post-1-possible-data-sets.html",
    "title": "Blog post 1: Possible data sets",
    "section": "",
    "text": "https://edopportunity.org/get-the-data/seda-archive-downloads/\nSEDA is a long-term project working to standardize state test scores in order to make them comparable between states. As each state implements their own statewide standardized tests for each grade level with different scoring scales, it is normally quite challenging to perform a direct comparison of differences between states. SEDA aims to resolve that, with available data on individual school performance all the way up to statewide performance, covering math and reading tests for multiple grade levels. We are thinking we would use district-level data, as that would allow for a lot of detailed work if we choose to focus on a specific region. They also have an extensive file of different covariates for each district with percentages of different racial groups, gender, poverty levels, and other interesting variables. The files are easily accessible and well-documented, with the most recent dataset spanning from 2009-2018 and detailed codebooks available for each geographic grouping level. Their methodology is explained on their website. We downloaded the seda_cov_geodist_long_4.1 and seda_geodist_long_gcs_4.1 files. The initial datafiles are quite large (~700,000 and ~1,200,000 observations, respectively), so even though they are very nicely organized and polished, we were not able to upload them to our repository without some compressing. We were able to collapse each file by year and district. Instead of having an observation for six or seven different grade levels for each year for each district, there was only one observation for each district per year, taking the mean for each selected column across all grades. We also removed some of the variable columns that seemed less relevant to what we were thinking about for potential questions–mostly related to how certain covariates like poverty and race interact and how they might affect test scores. With these edits, we were able to get the files to a size that could be easily shared while still containing huge amounts of relevant information for any potential education inequality related project we might choose to do."
  },
  {
    "objectID": "posts/2024-03-04-blog-post-1-possible-data-sets/blog-post-1-possible-data-sets.html#option-1-stanford-education-data-archive",
    "href": "posts/2024-03-04-blog-post-1-possible-data-sets/blog-post-1-possible-data-sets.html#option-1-stanford-education-data-archive",
    "title": "Blog post 1: Possible data sets",
    "section": "",
    "text": "https://edopportunity.org/get-the-data/seda-archive-downloads/\nSEDA is a long-term project working to standardize state test scores in order to make them comparable between states. As each state implements their own statewide standardized tests for each grade level with different scoring scales, it is normally quite challenging to perform a direct comparison of differences between states. SEDA aims to resolve that, with available data on individual school performance all the way up to statewide performance, covering math and reading tests for multiple grade levels. We are thinking we would use district-level data, as that would allow for a lot of detailed work if we choose to focus on a specific region. They also have an extensive file of different covariates for each district with percentages of different racial groups, gender, poverty levels, and other interesting variables. The files are easily accessible and well-documented, with the most recent dataset spanning from 2009-2018 and detailed codebooks available for each geographic grouping level. Their methodology is explained on their website. We downloaded the seda_cov_geodist_long_4.1 and seda_geodist_long_gcs_4.1 files. The initial datafiles are quite large (~700,000 and ~1,200,000 observations, respectively), so even though they are very nicely organized and polished, we were not able to upload them to our repository without some compressing. We were able to collapse each file by year and district. Instead of having an observation for six or seven different grade levels for each year for each district, there was only one observation for each district per year, taking the mean for each selected column across all grades. We also removed some of the variable columns that seemed less relevant to what we were thinking about for potential questions–mostly related to how certain covariates like poverty and race interact and how they might affect test scores. With these edits, we were able to get the files to a size that could be easily shared while still containing huge amounts of relevant information for any potential education inequality related project we might choose to do."
  },
  {
    "objectID": "posts/2024-03-04-blog-post-1-possible-data-sets/blog-post-1-possible-data-sets.html#option-2-us-police-shooting-dataset",
    "href": "posts/2024-03-04-blog-post-1-possible-data-sets/blog-post-1-possible-data-sets.html#option-2-us-police-shooting-dataset",
    "title": "Blog post 1: Possible data sets",
    "section": "Option 2: US police shooting dataset",
    "text": "Option 2: US police shooting dataset\nhttps://www.kaggle.com/datasets/ahsen1330/us-police-shootings?resource=download\nThe dataset was collected from Kaggle.com, and the dataset comprises records of police shooting incidents in the United States, including a total of 4896 rows, each representing an individual case, and 15 columns, which document various attributes associated with each incident, such as the date, manner of death, and demographics of the individual involved (including age, gender, and race), etc. Moreover, we can clean the dataset by organizing variables, such as the manner of death and types of arms, to numerical data and filter out the rows that contain missing values. In exploring this data, the primary goal is to examine and analyze racial disparities and criminal justice within the context of police shootings. Anticipated challenges include navigating through potential biases in data reporting and incomplete information about individual cases."
  },
  {
    "objectID": "posts/2024-03-04-blog-post-1-possible-data-sets/blog-post-1-possible-data-sets.html#option-3-health-insurance-coverage-in-the-us-in-2022",
    "href": "posts/2024-03-04-blog-post-1-possible-data-sets/blog-post-1-possible-data-sets.html#option-3-health-insurance-coverage-in-the-us-in-2022",
    "title": "Blog post 1: Possible data sets",
    "section": "Option 3: Health Insurance Coverage in the US in 2022",
    "text": "Option 3: Health Insurance Coverage in the US in 2022\nhttps://www.census.gov/library/publications/2023/demo/p60-281.html\nThe dataset “Health Insurance Coverage in the United States: 2022,” sourced from the United States Census Bureau, offers detailed insights into the health insurance landscape across the nation for the year 2022. It includes information on various aspects of health insurance coverage, such as the number of insured individuals, coverage rates, types of insurance (e.g., private, public), demographic breakdowns, work experience, education level, income-to-poverty ratio, and incomes per household. We can utilize this dataset to conduct analysis aimed at understanding patterns of health insurance coverage, identifying populations with high rates of uninsurance, assessing the impact of policy changes on coverage rates, and exploring disparities in access to health care services. Moreover, we can investigate the relationship between health insurance coverage and health outcomes, healthcare utilization patterns, and financial burden due to medical expenses. One challenge to using this data is the amount of cleaning necessary to get this into a usable format. This data is not in a clear format so our ability to upload it may be compromised."
  },
  {
    "objectID": "posts/2024-04-19-blog-post-6-thesis-and-continuing-exploration/blog-post-6-thesis-and-continuing-exploration.html",
    "href": "posts/2024-04-19-blog-post-6-thesis-and-continuing-exploration/blog-post-6-thesis-and-continuing-exploration.html",
    "title": "Blog Post 6: Thesis and Continuing Exploration",
    "section": "",
    "text": "To narrow down to certain states, we will focus on Massachusetts and Mississippi. Massachusetts is the most educated state in the US, and Mississippi is the least educated state."
  },
  {
    "objectID": "posts/2024-04-19-blog-post-6-thesis-and-continuing-exploration/blog-post-6-thesis-and-continuing-exploration.html#thesis",
    "href": "posts/2024-04-19-blog-post-6-thesis-and-continuing-exploration/blog-post-6-thesis-and-continuing-exploration.html#thesis",
    "title": "Blog Post 6: Thesis and Continuing Exploration",
    "section": "Thesis",
    "text": "Thesis\nMississippi, with its higher percentage of economically disadvantaged students, higher poverty rate, higher unemployment rate, lower percentage of parents holding bachelor’s degrees, and lower median income, has lower mean scores in both language and math for all students compared to Massachusetts."
  },
  {
    "objectID": "posts/2024-04-19-blog-post-6-thesis-and-continuing-exploration/blog-post-6-thesis-and-continuing-exploration.html#more-exploration-of-independent-variables",
    "href": "posts/2024-04-19-blog-post-6-thesis-and-continuing-exploration/blog-post-6-thesis-and-continuing-exploration.html#more-exploration-of-independent-variables",
    "title": "Blog Post 6: Thesis and Continuing Exploration",
    "section": "More Exploration of Independent Variables",
    "text": "More Exploration of Independent Variables\n\nMassachusetts\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\n\nMississippi\n\n\n\n\n\nAfter observing each plot for the variables, all variables are skewed except for the median income and the mean score. Therefore, we will apply natural log or square root transformations for those variables to deal with the skewness.\n\nlibrary(tidyverse)\n\nselected_variables_MS &lt;- mississippi_data %&gt;%\n  select(perasn, perblk, perecd, perwht, unempall, baplusall) %&gt;%\n  filter(perasn &gt; 0 & perblk &gt; 0 & perecd &gt; 0 & perwht &gt; 0 & unempall &gt; 0)\n\nselected_variables_MS_log &lt;- selected_variables_MS %&gt;%\n  mutate(across(everything(), log))\n\nselected_variables_MS_sqrt &lt;- selected_variables_MS %&gt;%\n  mutate(across(everything(), sqrt))\n\nselected_variables_MS_log %&gt;%\n  gather(key = \"variable\", value = \"value\") %&gt;%\n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\") +\n  facet_wrap(~ variable, scales = \"free\") +\n  labs(title = \"Histograms of Log-Transformed Variables for MS Districts\",\n       x = \"Log-transformed Value\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\nselected_variables_MS_sqrt %&gt;%\n  gather(key = \"variable\", value = \"value\") %&gt;%\n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\") +\n  facet_wrap(~ variable, scales = \"free\") +\n  labs(title = \"Histograms of Square Root Transformed Variables for MS Districts\",\n       x = \"Square Root Transformed Value\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\nSince some of the variables are still skewed, we will find more potential transformations or use a Robust Regression model that is less sensitive to outliers and skewness."
  },
  {
    "objectID": "posts/2024-04-10-blog-post-5-the-second-dataset/blog-post-5-the-second-dataset.html",
    "href": "posts/2024-04-10-blog-post-5-the-second-dataset/blog-post-5-the-second-dataset.html",
    "title": "Blog Post 5: The Second Dataset",
    "section": "",
    "text": "In our ongoing quest to extract meaningful insights from educational data, we’ve recently enhanced our dataset with the inclusion of three pivotal new variables. Sourced from the Stanford Education Data Archive (SEDA), these additions—lninc50all, baplusall, and povertyall—represent, respectively, the natural logarithm of the median income across all datasets, the percentage of parents holding at least a Bachelor’s degree, and the overall poverty rate. This data enrichment is performed with the intention of capturing a more nuanced picture of educational disparities on a state level, year by year. To ensure the integrity of our analysis, meticulous steps were taken to filter out any instances of missing values, thus maintaining the robustness of our research framework.\nAs we stand, the datasets have been methodically merged, organizing the newly adopted variables in alignment with the existing structure based on state and temporal parameters. Preliminary scrutiny of the enhanced dataset reveals promising avenues for exploration. For instance, the incorporation of lninc50all allows us to investigate the elasticity of educational outcomes in relation to median income, while baplusall and povertyall offer a lens to examine the correlation between parental education, poverty levels, and educational equity. As we delve deeper into the data, our next steps will be geared towards applying advanced analytical models to discern patterns and potentially causal relationships. Stay tuned as we continue to unfold the narratives hidden within the numbers, with the ultimate aim of informing policies that bridge educational gaps.\nLink for the new dataset: https://edopportunity.org/get-the-data/seda-archive-downloads/"
  },
  {
    "objectID": "posts/2024-04-10-blog-post-5-the-second-dataset/blog-post-5-the-second-dataset.html#our-secondary-dataset",
    "href": "posts/2024-04-10-blog-post-5-the-second-dataset/blog-post-5-the-second-dataset.html#our-secondary-dataset",
    "title": "Blog Post 5: The Second Dataset",
    "section": "",
    "text": "In our ongoing quest to extract meaningful insights from educational data, we’ve recently enhanced our dataset with the inclusion of three pivotal new variables. Sourced from the Stanford Education Data Archive (SEDA), these additions—lninc50all, baplusall, and povertyall—represent, respectively, the natural logarithm of the median income across all datasets, the percentage of parents holding at least a Bachelor’s degree, and the overall poverty rate. This data enrichment is performed with the intention of capturing a more nuanced picture of educational disparities on a state level, year by year. To ensure the integrity of our analysis, meticulous steps were taken to filter out any instances of missing values, thus maintaining the robustness of our research framework.\nAs we stand, the datasets have been methodically merged, organizing the newly adopted variables in alignment with the existing structure based on state and temporal parameters. Preliminary scrutiny of the enhanced dataset reveals promising avenues for exploration. For instance, the incorporation of lninc50all allows us to investigate the elasticity of educational outcomes in relation to median income, while baplusall and povertyall offer a lens to examine the correlation between parental education, poverty levels, and educational equity. As we delve deeper into the data, our next steps will be geared towards applying advanced analytical models to discern patterns and potentially causal relationships. Stay tuned as we continue to unfold the narratives hidden within the numbers, with the ultimate aim of informing policies that bridge educational gaps.\nLink for the new dataset: https://edopportunity.org/get-the-data/seda-archive-downloads/"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html",
    "href": "posts/2023-12-20-examples/examples.html",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "href": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2024-03-25-blog-post-2-data-background/blog-post-2-data-background.html",
    "href": "posts/2024-03-25-blog-post-2-data-background/blog-post-2-data-background.html",
    "title": "Blog Post 2: Data Background",
    "section": "",
    "text": "Our data comes from the Stanford Education Data Archive, also known as SEDA. This is a project conducted by researches at the Stanford Graduate School of Education.The purpose of SEDA is to provide comprehensive, publicly available data on U.S. K-12 education. The data is primarily gathered for academic research, policy analysis, and accountability purposes. Researchers utilize it to study educational disparities, policy effectiveness, and the impact of various interventions. Policymakers rely on this data to make informed decisions, allocate resources, and hold stakeholders accountable for student outcomes. Despite persistent racial, socioeconomic, and gender disparities in academic performance and educational attainment within the U.S. educational system, SEDA emphasizes that these gaps are not inevitable or unchangeable.\nThe data is collected from various sources, including the U.S. Department of Education, state education agencies, and other publicly available datasets. It includes information on student demographics, achievement outcomes, funding, and other factors relevant to understanding educational disparities and opportunities across different regions and demographics. The advantage of SEDA is that it aggregates and organizes the data.\nSEDA combines information from the National Assessment of Educational Progress regarding the test scores in each school, geographic district, county, or state to compare scores from state tests on a common national level"
  },
  {
    "objectID": "posts/2024-03-25-blog-post-2-data-background/blog-post-2-data-background.html#where-does-our-data-come-from",
    "href": "posts/2024-03-25-blog-post-2-data-background/blog-post-2-data-background.html#where-does-our-data-come-from",
    "title": "Blog Post 2: Data Background",
    "section": "",
    "text": "Our data comes from the Stanford Education Data Archive, also known as SEDA. This is a project conducted by researches at the Stanford Graduate School of Education.The purpose of SEDA is to provide comprehensive, publicly available data on U.S. K-12 education. The data is primarily gathered for academic research, policy analysis, and accountability purposes. Researchers utilize it to study educational disparities, policy effectiveness, and the impact of various interventions. Policymakers rely on this data to make informed decisions, allocate resources, and hold stakeholders accountable for student outcomes. Despite persistent racial, socioeconomic, and gender disparities in academic performance and educational attainment within the U.S. educational system, SEDA emphasizes that these gaps are not inevitable or unchangeable.\nThe data is collected from various sources, including the U.S. Department of Education, state education agencies, and other publicly available datasets. It includes information on student demographics, achievement outcomes, funding, and other factors relevant to understanding educational disparities and opportunities across different regions and demographics. The advantage of SEDA is that it aggregates and organizes the data.\nSEDA combines information from the National Assessment of Educational Progress regarding the test scores in each school, geographic district, county, or state to compare scores from state tests on a common national level"
  },
  {
    "objectID": "posts/2024-03-25-blog-post-2-data-background/blog-post-2-data-background.html#what-is-reported",
    "href": "posts/2024-03-25-blog-post-2-data-background/blog-post-2-data-background.html#what-is-reported",
    "title": "Blog Post 2: Data Background",
    "section": "What is reported?",
    "text": "What is reported?\nThe raw data includes only counts of students scoring at different test-score levels, not individual test scores.This data includes constructed margin of errors for each of the measures of average test scores, learning rate, and trends in average scores with 95% confidence intervals. The data does not report average performance, learning, and/or trends if there were fewer than 20 students represented in the estimate, more than 30% of students in the unit took alternative assessments, or if the estimates are too imprecise to be informative."
  },
  {
    "objectID": "posts/2024-03-25-blog-post-2-data-background/blog-post-2-data-background.html#what-issues-do-we-predict",
    "href": "posts/2024-03-25-blog-post-2-data-background/blog-post-2-data-background.html#what-issues-do-we-predict",
    "title": "Blog Post 2: Data Background",
    "section": "What issues do we predict?",
    "text": "What issues do we predict?\nThere could be a possible bias in the learning-rate estimates towards districts with high-achieving kids moving out and low-achieving kids moving in, in the later years. Consequently, the data would be underestimating the learning rate in a school or district."
  },
  {
    "objectID": "posts/2024-03-25-blog-post-2-data-background/blog-post-2-data-background.html#who-has-used-this-data",
    "href": "posts/2024-03-25-blog-post-2-data-background/blog-post-2-data-background.html#who-has-used-this-data",
    "title": "Blog Post 2: Data Background",
    "section": "Who has used this data?",
    "text": "Who has used this data?\nThe Stanford Education Data Archive (SEDA) has been instrumental in education policy and economics research, providing crucial insights into the educational impacts of COVID-19 through studies such as “The First Year of Pandemic Recovery: A District-Level Analysis” and “School District and Community Factors Associated With Learning Loss During the COVID-19 Pandemic”. These investigations delve into the significant shifts to remote learning and the associated declines in math and reading achievements, offering a district-level perspective on the pandemic’s profound effects on education. Moreover, by examining data from 7,800 districts, the research explores how income levels, minority status, and the extent of remote instruction have influenced learning losses, shedding light on the complex interplay of external factors affecting educational outcomes during this unprecedented time."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Final Project due May 7, 2024 at 11:59pm.\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 6: Thesis and Continuing Exploration\n\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2024\n\n\nGroup 10\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 7: Polishing\n\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2024\n\n\nGroup 10\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 5: The Second Dataset\n\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2024\n\n\nGroup 10\n\n\n\n\n\n\n  \n\n\n\n\nBlog post 4: Exploring the Data\n\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2024\n\n\nGroup 10\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 3: Equity and Data Cleaning\n\n\n\n\n\nDiscussing what we did to clean our data and whether it is equitable\n\n\n\n\n\n\nApr 1, 2024\n\n\nGroup 10\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 2: Data Background\n\n\n\n\n\n\n\n\n\n\n\n\nMar 25, 2024\n\n\nGroup 10\n\n\n\n\n\n\n  \n\n\n\n\nBlog post 1: Possible data sets\n\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2024\n\n\nGroup 10\n\n\n\n\n\n\n  \n\n\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n  \n\n\n\n\nGetting started\n\n\n\n\n\n\n\n\n\n\nDirections to set up your website and create your first post.\n\n\n\n\n\n\nFeb 23, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n  \n\n\n\n\nFirst Team Meeting\n\n\n\n\n\n\n\n\n\n\nThis post details the steps you’ll take for your first team meeting.\n\n\n\n\n\n\nFeb 21, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team Group 10. The members of this team are below."
  },
  {
    "objectID": "about.html#aruzhan-bektemirova",
    "href": "about.html#aruzhan-bektemirova",
    "title": "About",
    "section": "Aruzhan Bektemirova",
    "text": "Aruzhan Bektemirova\nAruzhan is an undergraduate student in Economics and Mathematics and is enrolled in this course. https://github.com/aru-beka"
  },
  {
    "objectID": "about.html#yixiao-li",
    "href": "about.html#yixiao-li",
    "title": "About",
    "section": "Yixiao Li",
    "text": "Yixiao Li\nLi is an undergraduate student in Economics and Mathematics. https://github.com/YixiaoLi0922"
  },
  {
    "objectID": "about.html#chase-stephens",
    "href": "about.html#chase-stephens",
    "title": "About",
    "section": "Chase Stephens",
    "text": "Chase Stephens\nChase is an undergraduate student in Economics and Mathematics. https://github.com/chasedstephens"
  },
  {
    "objectID": "about.html#morgan-fleming",
    "href": "about.html#morgan-fleming",
    "title": "About",
    "section": "Morgan Fleming",
    "text": "Morgan Fleming\nMorgan is an undergraduate student in Economics and Mathematics. https://github.com/mlfleming"
  },
  {
    "objectID": "about.html#taelor-anderson",
    "href": "about.html#taelor-anderson",
    "title": "About",
    "section": "Taelor Anderson",
    "text": "Taelor Anderson\nTaelor is an undergraduate student in Psychology with a minor in Statistical Methods. https://github.com/taelorra\n\n\n\n\n\n\n\nc78b33d294cb3cec131c92a864c4bd81704aa588\n\n\n\n\n\n\n\n\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd.\nWe describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.\nThe style of this paper should aim to be that of an academic paper. I don’t expect this to be of publication quality but you should keep that aim in mind. Avoid using “we” too frequently, for example “We also found that …”. Describe your methodology and your findings but don’t describe your whole process."
  },
  {
    "objectID": "analysis.html#note-on-attribution",
    "href": "analysis.html#note-on-attribution",
    "title": "Analysis",
    "section": "Note on Attribution",
    "text": "Note on Attribution\nIn general, you should try to provide links to relevant resources, especially those that helped you. You don’t have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don’t need a formal citation.\nIf you are directly quoting from a source, please make that clear. You can show quotes using &gt; like this\n&gt; To be or not to be.\n\nTo be or not to be."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained, i.e. provide a description of the relevant data."
  },
  {
    "objectID": "big_picture.html#introduction",
    "href": "big_picture.html#introduction",
    "title": "Big Picture",
    "section": "Introduction",
    "text": "Introduction\nImagine two children, one in Massachusetts, the richest state in terms of educational attainment, and the other in Mississippi, ranked lowest on the same scale. Though separated by over a thousand miles, the distance is more than geographical—it’s educational, economic, and deeply rooted in the very fabric of society. This article dives into the complex interplay of socioeconomic factors that shape educational outcomes, revealing how deeply inequality is entrenched from one generation to the next."
  },
  {
    "objectID": "big_picture.html#thesis-statement",
    "href": "big_picture.html#thesis-statement",
    "title": "Big Picture",
    "section": "Thesis Statement",
    "text": "Thesis Statement\nIn Massachusetts and Mississippi, the chasm in educational outcomes extends beyond mere geography and taps directly into profound socioeconomic disparities. Our analysis, focusing on district-level data, demonstrates a stark correlation: in areas where economic disadvantage is more pronounced, educational performance, particularly in language and math, significantly declines."
  },
  {
    "objectID": "big_picture.html#data-and-methodology",
    "href": "big_picture.html#data-and-methodology",
    "title": "Big Picture",
    "section": "Data and Methodology",
    "text": "Data and Methodology\nOur study utilizes a comprehensive dataset encompassing district-level information from both states, including metrics on economically disadvantaged students, poverty rates, unemployment levels, median income, parental educational attainment, and racial demographics. By analyzing these variables, we aim to paint a detailed picture of how socioeconomic factors influence student performance across diverse communities.\n\nMassachusetts\n\n\n\n\n\n\n\nMississippi\n\n\n\n\n\nAs we journey through the educational terrain of Massachusetts and Mississippi, the contrasts are as stark as the shades of blue that paint our histograms. From the cobalt peaks representing Massachusetts’s highly educated parents to the navy troughs echoing Mississippi’s economic struggles, each bar tells a story.\nIn Massachusetts, the histogram showcasing parental education (‘baplusall’) is a mountain range of ambition, with a majority of districts featuring a high percentage of parents holding bachelor’s degrees. It’s a testament to the state’s rich educational foundation. Contrast this with Mississippi, where these peaks are notably subdued, hinting at a landscape where higher education is a distant summit for many.\nEconomic disadvantage (‘perecd’) casts long shadows across the Mississippi graph, where the frequency of high percentages is all too common, a reflection of the hardship many students face before they even step into a classroom. Massachusetts, while not immune to these challenges, shows a distribution with fewer districts at the higher end of economic disadvantage, suggesting a different kind of starting line for students.\nThe racial composition histograms (‘perblk’, ‘perasn’, ‘perwht’) are a mosaic of demographic diversity. Massachusetts’s ‘perwht’ bars rise high, a sign of racial homogeneity in many districts. Mississippi tells a different story, with ‘perblk’ significantly more represented, raising questions about how racial and economic factors interweave to shape educational outcomes.\nPoverty (‘povertyall’) and unemployment (‘unempall’) in Mississippi seem to walk hand in hand, with histograms skewing towards higher rates than those in Massachusetts. It’s a silent narrative of the daily challenges students bring with them to school, burdens that can weigh heavily on academic achievement."
  },
  {
    "objectID": "big_picture.html#analysis",
    "href": "big_picture.html#analysis",
    "title": "Big Picture",
    "section": "Analysis",
    "text": "Analysis\n\nEconomic Factors\nOur initial focus is on economic variables. Poverty and unemployment, often intertwined, emerge as significant predictors of educational success. Districts with higher poverty rates consistently show lower educational outcomes. This pattern underscores the critical role that economic stability plays in supporting academic achievement.\n\n\nEducational Background of Parents\nAnother striking factor is the educational attainment of parents. Districts where a higher percentage of parents hold bachelor’s degrees or higher often report better student performance. This relationship highlights the cyclical nature of education—where educational advantages and disadvantages are passed down through generations, potentially widening the gap.\n\n\nRacial Demographics\nFinally, the racial composition of districts also plays a critical role in educational outcomes. Our analysis indicates varied performance across different racial groups, with significant disparities evident between and within states. These findings provoke a broader discussion on the intersection of race, education, and socioeconomic status.\n\nOur exploration reveals a troubling yet clear picture: socioeconomic factors like poverty, unemployment, and parental education significantly influence educational outcomes in Massachusetts and Mississippi. This underscores the urgent need for policy interventions aimed at reducing educational disparities as a step towards greater social equity."
  },
  {
    "objectID": "big_picture.html#call-to-action",
    "href": "big_picture.html#call-to-action",
    "title": "Big Picture",
    "section": "Call to Action",
    "text": "Call to Action\nUnderstanding these disparities is just the beginning. We must now turn insights into action. By supporting policies that target educational equity—such as improving access to quality education, enhancing parental support programs, and addressing systemic poverty—we can begin to close this educational gap. Let’s commit to making a difference, not just in Massachusetts and Mississippi, but across the nation."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a story. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nInteractive\nYou will also be required to make an interactive dashboard like this one.\nYour Big Data page should include a link to an interactive dashboard. The dashboard should be created either using Shiny or FlexDashboard (or another tool with professor’s approval). This interactive component should in some way support your thesis from your big picture page. Good interactives often provide both high-level understanding of the data while allowing a user to investigate specific scenarios, observations, subgroups, etc.\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions from the Big Picture? Plotly with default hover text will get no credit. Be creative!\n\n\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "Our data comes from the Stanford Education Data Archive (SEDA). The purpose of SEDA is to provide comprehensive, publicly available data on U.S. K-12 education academic research, policy analysis, and accountability purposes. It is commonly sourced from for the study of educational disparities, policy effectiveness, and the impact of various interventions."
  },
  {
    "objectID": "data.html#our-data",
    "href": "data.html#our-data",
    "title": "Data",
    "section": "",
    "text": "Our data comes from the Stanford Education Data Archive (SEDA). The purpose of SEDA is to provide comprehensive, publicly available data on U.S. K-12 education academic research, policy analysis, and accountability purposes. It is commonly sourced from for the study of educational disparities, policy effectiveness, and the impact of various interventions."
  },
  {
    "objectID": "data.html#describe-wherehow-to-find-data-why-was-the-data-collectedcurated-who-put-it-together",
    "href": "data.html#describe-wherehow-to-find-data-why-was-the-data-collectedcurated-who-put-it-together",
    "title": "Data",
    "section": "Describe where/how to find data, Why was the data collected/curated? Who put it together?",
    "text": "Describe where/how to find data, Why was the data collected/curated? Who put it together?\nOur data comes from the Stanford Education Data Archive, SEDA. Researchers at the Stanford Graduate School of Education conducted this project. SEDA provides comprehensive, publicly available data on U.S. K-12 education. The data is primarily gathered for academic research, policy analysis, and accountability purposes.Researchers utilize it to study educational disparities, policy effectiveness, and the impact of various interventions. Policymakers rely on this data to make informed decisions, allocate resources, and hold stakeholders accountable for student outcomes. Link to the original data source: https://edopportunity.org/get-the-data/seda-archive-downloads/"
  },
  {
    "objectID": "data.html#describe-the-different-data-files-used-and-what-each-variable-means",
    "href": "data.html#describe-the-different-data-files-used-and-what-each-variable-means",
    "title": "Data",
    "section": "Describe the different data files used and what each variable means",
    "text": "Describe the different data files used and what each variable means\n\nDistrict: geographic school district\nSubject:\n\nRLA: Reading Language Arts\nMTH: Math\n\nMn_score: Average test scores\nNumstu: number of students\nPer: percentage of students in grade\nSubgroups:\n\nAll: all students\nAsn: Asian students\nBlk: Black students\nFem: female students\nHsp: Hispanic students\nMale: male students\nMtr: Multiracial students\nNec: Not economically disadvantaged\nWht: white students\n\nTotenrl: Number of students in grade\nUnempall: unemployment rate\nSnapall: Snap receipt rate\nSingle_momall: Single mother hh rate"
  },
  {
    "objectID": "data.html#describe-any-cleaning-you-had-to-do-for-your-data",
    "href": "data.html#describe-any-cleaning-you-had-to-do-for-your-data",
    "title": "Data",
    "section": "Describe any cleaning you had to do for your data",
    "text": "Describe any cleaning you had to do for your data\n\nWe cleaned our data before importing it, as it was 500mB. We kept the scores for each race and the locations, as we are most interested in those.\nWe downloaded the raw data and saved it in the data folder.\nUtilized the dplyr package to:\n\nSelect relevant attributes for the project.\nRemove unnecessary attributes.\nRemove missing attributes.\nRemove unusual values.\nUtilized the collapse package to collapse selected variables into their mean, creating one observation per year, district, class subject, and state combination. Previously it was expanded into grade levels, and finding the mean across those for each year allowed for compression of the very large original data set. The cleaned data was exported to the data folder.\n\nLink to load_and_clean_data.R file: loading script\n\n\nSummary of numerical variables\nTo begin, we wanted to make a summary table of general descriptive statistics for the races included in our data and the economically challenged students to see the variation between their test scores. This is not broken down by location yet, but we wanted to visualize the data better so we would know how to proceed.\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n  mn_score_all     mn_score_asn     mn_score_blk     mn_score_ecd  \n Min.   :-3.735   Min.   :-2.92    Min.   :-3.40    Min.   :-3.55  \n 1st Qu.:-0.197   1st Qu.: 0.26    1st Qu.:-0.63    1st Qu.:-0.42  \n Median : 0.030   Median : 0.60    Median :-0.45    Median :-0.24  \n Mean   : 0.025   Mean   : 0.59    Mean   :-0.44    Mean   :-0.26  \n 3rd Qu.: 0.249   3rd Qu.: 0.93    3rd Qu.:-0.25    3rd Qu.:-0.08  \n Max.   : 2.865   Max.   : 2.79    Max.   : 1.16    Max.   : 1.24  \n NA's   :23236    NA's   :205143   NA's   :180838   NA's   :61961  \n\n\nBy examining these histograms, we visually analyze the distribution of test scores within each subgroup. This visualization helps us understand the spread, central tendency, and potential outliers within the test scores across different racial groups and economic statuses.\n\n\n[conflicted] Will prefer dplyr::filter over any other package."
  }
]