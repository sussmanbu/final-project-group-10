---
title: Analysis
description: Here we provide a detailed analysis using more sophisticated statistics techniques.
toc: true
draft: false
---

![](images/analysis%20page.jpeg)

This comes from the file `analysis.qmd`.



## Note on Attribution

In general, you should try to provide links to relevant resources, especially those that helped you. You don't have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don't need a formal citation.

If you are directly quoting from a source, please make that clear. You can show quotes using `>` like this






# Motivation and Research

## Motivation
We aim to analyze how economic disadvantage correlates with educational performance in language and math across districts within the two states, examining the extent to which factors like median income and unemployment rates influence student performance. Our study also compares the educational outcomes between the two states to assess whether variations in economic conditions contribute to differences in performance. Additionally, we consider the role of racial demographics in this context, investigating how economic disparities affect different racial groups regarding their educational success. Finally, we look at the consistency of these relationships over time to identify any trends or changes, enhancing our understanding of how economic factors have historically influenced educational outcomes.

## Relationship Exploration


# Models

## Outline
1. Weighted Regression Model
2. Robust Regression Model

## 1. Weighted Regression Model

### Models Overview
Since some of the variables are not normally distributed, we decided to use weighted and robust regression models to address these issues. This linear regression model examines the impact of various socioeconomic and demographic factors on mean student scores across districts in Massachusetts. It incorporates variables such as the percentage of economically disadvantaged students (perecd), poverty rate (povertyall), unemployment rate (unempall), natural logarithm of median income (lninc50all), and the percentage of parents with at least a bachelor's degree (baplusall), along with racial demographics (perblk, perasn, perwht). The weighted regression approach is employed to adjust for potential biases or imbalances in the dataset.

### Massachusetts Weighted Regression Model

```{r, echo=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(kableExtra))
library(tidyverse)
library(dplyr)
library(readr)
library(broom)
library(knitr)
library(jtools)
library(kableExtra)
cleaned_seda <- read_rds("dataset/cleaned_seda.rds")

massachusetts_data <- cleaned_seda %>%
  filter(state == "MA")

selected_variables_MA <- massachusetts_data %>%
  dplyr::select(mn_score_all, perecd, povertyall, unempall, lninc50all, baplusall, perblk, perasn, perwht) %>%
  filter(if_all(everything(), is.finite))

weights <- 1/selected_variables_MA$povertyall 

weighted_regression_MA <- lm(mn_score_all ~ perecd + povertyall + unempall + lninc50all + baplusall + perblk + perasn + perwht, 
                          data = selected_variables_MA,
                          weights = weights)

summ(weighted_regression_MA, type="text") 
```
The model explains approximately 76.59% of the variance in the mean score for all students in the dataset.

### MA Weighted Regression Model Residual Plots
The values on this plot appear to be randomly distributed around the zero line, indicating that the assumption of constant variance (homoscedasticity) and linearity is satisfied.
```{r, echo=FALSE}
residuals_vs_fitted <- ggplot(data = augment(weighted_regression_MA), aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Residuals vs. Fitted Values",
       x = "Fitted Values",
       y = "Residuals")


print(residuals_vs_fitted)

```

### Visualization of Coefficients
```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
suppressPackageStartupMessages(library(tidyverse))
library(tidyverse)
library(dplyr)
library(readr)
library(broom)
library(forestplot)

regMA <- tidy(weighted_regression_MA)

regMA <- regMA %>% 
  mutate(upper = estimate + std.error) %>% 
  mutate(lower = estimate - std.error)  

regMA = regMA[-c(1),]

y_labels <- c( "Economically Disadv",
   "Poverty",
    "Unemployment",
    "Income (50th Percentile)",
    "Parent Education",
    "Black or AA",
"Asian",
"White")

forestplot(
mean = regMA$estimate,
 lower = regMA$lower,
  upper = regMA$upper,
 labeltext = y_labels,
 xlab = "Adjusted Coefficients and 95% Confidence Intervals",
 cex = 0.8,
  boxsize = 0.18,
  lwd.ci= 2,
  lineheight = "lines",
  col = fpColors(box = "#0077BB", line = "black", summary = "darkgreen"),
  graph.pos = 2,  # Position of the forest plot graph      # Font size
  grid = TRUE,
  title = "Weighted Regression Model for Massachussets"
)

```

### Interpretation for MA Weighted Regression Model
```{r, echo = FALSE}
coefficients_table <- data.frame(
  Term = c("Intercept", "perecd", "povertyall", "unempall", 
           "lninc50all", "baplusall", "perblk", "perasn", "perwht", "R-squared"),
  Estimate = c(0.74363, -0.83297, -0.75291, 2.16004, 
               -0.06063, 0.92817, -0.15714, 0.93507, 0.12889, 0.7659),
  Interpretation = c(
    "Baseline mean score for all students, when all predictors are at zero.",
    "For each percentage point increase in economically disadvantaged students, there is an expected decrease of approximately 0.833 in the mean score.",
    "For each percentage point increase in poverty rate, there is an expected decrease of approximately 0.753 in the mean score.",
    "For each percentage point increase in unemployment rate, there is an unexpected increase of approximately 2.160 in the mean score.",
    "A 1% increase in median income is associated with a decrease of 0.061 in the mean score, indicating a complex relationship with other socioeconomic factors.",
    "For each percentage point increase in the percentage of parents with a bachelor's degree or higher, there is an expected increase of approximately 0.928 in the mean score.",
    "For each percentage point increase in the percentage of Black students, there is an expected decrease of approximately 0.157 in the mean score.",
    "For each percentage point increase in the percentage of Asian students, there is an expected increase of approximately 0.935 in the mean score.",
    "For each percentage point increase in the percentage of White students, there is an expected but smaller increase of approximately 0.129 in the mean score.", 
    "The model explains approximately 76.59% of the variance in the mean score for all students in the dataset."
  )
)


kable(coefficients_table, format = "markdown", 
      col.names = c("Term", "Coefficient Estimate", "Interpretation"),
      caption = "Interpretations of Weighted Regression Model Coefficients for Massachusetts")
```

### Mississippi Weighted Regression Model

```{r, echo=FALSE}
cleaned_seda <- read_rds("dataset/cleaned_seda.rds")

mississippi_data <- cleaned_seda %>%
  filter(state == "MS")

selected_variables_MS <- mississippi_data %>%
  dplyr::select(mn_score_all, perecd, povertyall, unempall, lninc50all, baplusall, perblk, perasn, perwht) %>%
  filter(if_all(everything(), is.finite))

weights <- 1/selected_variables_MS$povertyall

weighted_regression_MS <- lm(mn_score_all ~ perecd + povertyall + unempall + lninc50all + baplusall + perblk + perasn + perwht, 
                          data = selected_variables_MS,
                          weights = weights)

summ(weighted_regression_MS)
```
The model explains approximately 0.68% of the variance in the mean score for all students in the dataset.

### MS Weighted Regression Model Residual Plots
The values on this plot appear to be randomly distributed around the zero line, indicating that the assumption of constant variance (homoscedasticity) and linearity is satisfied.
```{r, echo=FALSE, warning=FALSE}
residuals_vs_fitted <- ggplot(data = augment(weighted_regression_MS), aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Residuals vs. Fitted Values",
       x = "Fitted Values",
       y = "Residuals")
print(residuals_vs_fitted)
```

### Visualization of Coefficients
```{r, echo=FALSE, warning=FALSE}
library(tidyverse)
library(dplyr)
library(readr)
library(broom)
library(forestplot)
regMS <- tidy(weighted_regression_MS)

regMS <- regMS %>% 
  mutate(upper = estimate + std.error) %>% 
  mutate(lower = estimate - std.error)  
  
regMS = regMS[-c(1),]

y_labels <- c( "Economically Disadv",
   "Poverty",
    "Unemployment",
    "Income (50th Percentile)",
    "Parent Education",
    "Black or AA",
"Asian",
"White")


forestplot(
  mean = regMS$estimate,
  lower = regMS$lower,
  upper = regMS$upper,
  labeltext = y_labels,
  xlab = "Adjusted Coefficients and 95% Confidence Intervals",
  boxsize = 0.18,
  lwd.ci= 2,
  lineheight = "lines",
  col = fpColors(box = "#00CC66", line = "black", summary = "steelblue"),
  graph.pos = 2,  # Position of the forest plot graph
  cex = 0.8,      # Font size
  grid = TRUE,
  title = "Weighted Regression Model for Mississippi"
)
```

### Interpretation for MS Weighted Regression Model

```{r, echo=FALSE}
coefficients_table_mississippi <- data.frame(
  Term = c("Intercept", "perecd", "povertyall", "unempall", 
           "lninc50all", "baplusall", "perblk", "perasn", "perwht", "R-squared"),
  Estimate = c(2.31107, -0.22535, -0.75443, -0.72945, 
               -0.19933, 0.93576, -0.56360, 3.80540, -0.05968, 0.6752),
  Interpretation = c(
    "Baseline mean score for all students, when all predictors are at zero.",
    "For each percentage point increase in economically disadvantaged students, there is an expected decrease of approximately 0.225 in the mean score.",
    "For each percentage point increase in poverty rate, there is an expected decrease of approximately 0.754 in the mean score.",
    "For each percentage point increase in unemployment rate, there is an expected decrease of approximately 0.729 in the mean score.",
    "A 1% increase in median income is associated with a decrease of 0.199 in the mean score, indicating a complex relationship with other socioeconomic factors.",
    "For each percentage point increase in the percentage of parents with a bachelor's degree or higher, there is an expected increase of approximately 0.936 in the mean score.",
    "For each percentage point increase in the percentage of Black students, there is an expected decrease of approximately 0.564 in the mean score.",
    "For each percentage point increase in the percentage of Asian students, there is an expected increase of approximately 3.805 in the mean score.",
    "For each percentage point increase in the proportion of White students, there is an expected decrease of approximately 0.060 in the mean score, although this effect is not statistically significant (p-value: 0.435).",
    "The model explains approximately 67.52% of the variance in the mean score for all students in the dataset."
  )
)


kable(coefficients_table_mississippi, format = "markdown", 
      col.names = c("Term", "Coefficient Estimate", "Interpretation"),
      caption = "Interpretations of Weighted Regression Model Coefficients for Mississippi")

```

### Potential Flaws and Limitations
While one goal of weighted regression might be to reduce the influence of outliers by assigning them lower weights, if not properly managed, outliers with incorrectly assigned high weights can disproportionately influence the model, leading to skewed results. Moreover, the effectiveness of weighted regression often depends on the availability and accuracy of external information to assign weights, which could compromise the reliability of the weighting scheme.

## 2. Robust Regression Model

### Massachusetts Robust Regression Model

```{r, echo=FALSE}
library(tidyverse)
library(dplyr)
library(readr)
library(sandwich)
suppressPackageStartupMessages(library(MASS))

cleaned_seda <- read_rds("dataset/cleaned_seda.rds")
massachusetts_data <- cleaned_seda %>%
  filter(state == "MA")

selected_variables_MA <- massachusetts_data %>%
  dplyr::select(mn_score_all, perecd, povertyall, unempall, lninc50all, baplusall, perblk, perasn, perwht) %>%
  filter(if_all(everything(), is.finite))


robust_model_MA <- rlm(mn_score_all ~ perecd + povertyall + unempall + lninc50all + baplusall + perblk + perasn + perwht, data = selected_variables_MA)
  

robust_residuals_MA <- residuals(robust_model_MA)


tss <- sum((selected_variables_MA$mn_score_all - mean(selected_variables_MA$mn_score_all))^2)


rss <- sum(robust_residuals_MA^2)


pseudo_r_squared <- 1 - rss/tss

summary(robust_model_MA)
cat("Pseudo R-squared: ", pseudo_r_squared, "\n")
jtools::get_robust_se(robust_model_MA)
```

```{r, echo=FALSE}
suppressPackageStartupMessages(library(tidyverse))
library(tidyverse)
library(dplyr)
library(readr)
library(broom)
library(forestplot)

robregMA <- tidy(robust_model_MA)

robregMA <- robregMA %>% 
  mutate(upper = estimate + std.error) %>% 
  mutate(lower = estimate - std.error)  

robregMA = robregMA[-c(1),]

y_labels <- c( "Economically Disadv",
   "Poverty",
    "Unemployment",
    "Income (50th Percentile)",
    "Parent Education",
    "Black or AA",
"Asian",
"White")

xlab_set <- expression(italics("Adjusted Coefficients and 95% Confidence Intervals"), )
forestplot(
  mean = robregMA$estimate,
  lower = robregMA$lower,
  upper = robregMA$upper,
  labeltext = y_labels,
  xlab = "Adjusted Coefficients and 95% Confidence Intervals",
  cex = 0.8,
  boxsize=0.18,
  lwd.ci= 2,
  lineheight = "lines",
  col = fpColors(box = "#0077BB", line = "black", summary = "darkgreen"),
  graph.pos = 2,  # Position of the forest plot graph      # Font size
  grid = TRUE,
  title = "Robust Regression Model for Massachussets"
)
```

### Interpretation for MA Robust Regression Model

```{r, echo=FALSE}
suppressPackageStartupMessages(library(gridExtra))
library(knitr)

interpretations_df <- data.frame(
  Variable = c("(Intercept)", "perecd", "povertyall", "unempall", 
               "lninc50all", "baplusall", "perblk", "perasn", "perwht", "R-squared"),
  Coefficient = c(0.6881, -0.8944, -0.7035, 2.1884, -0.0418, 0.8714, -0.3181, 0.7202, -0.0039, 0.7697),
  Interpretation = c(
    "Baseline mean score for all students on the logged scale when all predictors are at zero.",
    "Each percentage point increase in economically disadvantaged students is associated with a 0.8944 point decrease in mean score.",
    "Each percentage point increase in poverty rate is associated with a 0.7035 point decrease in mean score.",
    "Each percentage point increase in unemployment rate is associated with a 2.1884 point increase in mean score, which is counterintuitive.",
    "A 1% increase in median income (not logged) is associated with a 0.0418 point decrease in mean score, which may indicate the presence of other interacting variables.",
    "Each percentage point increase in the proportion of parents with a bachelor's degree is associated with a 0.8714 point increase in mean score.",
    "Each percentage point increase in the proportion of Black students is associated with a 0.3181 point decrease in mean score.",
    "Each percentage point increase in the proportion of Asian students is associated with a 0.7202 point increase in mean score.",
    "Each percentage point increase in the proportion of White students is associated with a negligible change in mean score.",
    "The model explains approximately 76.97% of the variance in the mean score for all students in the dataset."
  )
)

kable(interpretations_df, format = "markdown", caption = "Interpretations of the Robust Regression Model Coefficients")
```

## Mississippi Robust Regression Model

```{r, echo=FALSE}
suppressPackageStartupMessages(library(gridExtra))
library(tidyverse)
library(dplyr)
library(readr)
library(MASS)

mississippi_data <- cleaned_seda %>%
  filter(state == "MS")

selected_variables_MS <- mississippi_data %>%
  dplyr::select(mn_score_all, perecd, povertyall, unempall, lninc50all, baplusall, perblk, perasn, perwht) %>%
  filter(if_all(everything(), is.finite))

robust_model_MS <- rlm(mn_score_all ~ perecd + povertyall + unempall + lninc50all + baplusall + perblk + perasn + perwht, data = selected_variables_MS)
  

robust_residuals_MS <- residuals(robust_model_MS)


tss <- sum((selected_variables_MS$mn_score_all - mean(selected_variables_MS$mn_score_all))^2)


rss <- sum(robust_residuals_MS^2)


pseudo_r_squared <- 1 - rss/tss

summary(robust_model_MS)
cat("Pseudo R-squared: ", pseudo_r_squared, "\n")
```

### MS Robust Regression Forest Plot

```{r, echo=FALSE}
library(tidyverse)
library(dplyr)
library(readr)
library(broom)
library(forestplot)
robregMS <- tidy(robust_model_MS)

robregMS <- robregMS %>% 
  mutate(upper = estimate + std.error) %>% 
  mutate(lower = estimate - std.error)  
  
robregMS = robregMS[-c(1),]

y_labels <- c( "Economically Disadv",
   "Poverty",
    "Unemployment",
    "Income (50th Percentile)",
    "Parent Education",
    "Black or AA",
"Asian",
"White")

forestplot(
  mean = robregMS$estimate,
  lower = robregMS$lower,
  upper = robregMS$upper,
  labeltext = y_labels,
  xlab = "Adjusted Coefficients and 95% Confidence Intervals",
  boxsize=0.18,
  lwd.ci= 2,
  lineheight = "lines",
  col = fpColors(box = "#00CC66", line = "black", summary = "steelblue"),
    graph.pos = 2,  # Position of the forest plot graph
  cex = 0.8,      # Font size
  grid = TRUE,
  title = "Robust Regression Model for Mississippi"
)
```

### Interpretation for MS Robust Regression Model

```{r, echo=FALSE}
suppressPackageStartupMessages(library(gridExtra))
library(knitr)

interpretations_df <- data.frame(
  Variable = c("Intercept", "perecd", "povertyall", "unempall", 
               "lninc50all", "baplusall", "perblk", "perasn", "perwht", "R-squared"),
  Coefficient = c(2.3299, -0.2273, -0.7626, -0.6635, -0.2040, 0.9211, -0.5384, 4.3782, -0.0387, 0.6625),
  Interpretation = c(
    "Baseline mean score for all students on the logged scale when all predictors are at zero.",
    "Each percentage point increase in economically disadvantaged students is associated with a 0.2273 point decrease in mean score.",
    "Each percentage point increase in poverty rate is associated with a 0.7626 point decrease in mean score.",
    "Each percentage point increase in unemployment rate is associated with a 0.6635 point decrease in mean score.",
    "A 1% increase in median income (on the natural log scale) is associated with a 0.2040 point decrease in mean score.",
    "Each percentage point increase in the proportion of parents with a bachelor's degree is associated with a 0.9211 point increase in mean score.",
    "Each percentage point increase in the proportion of Black students is associated with a 0.5384 point decrease in mean score.",
    "Each percentage point increase in the proportion of Asian students is associated with a 4.3782 point increase in mean score.",
    "Each percentage point increase in the proportion of White students is associated with a 0.0387 point decrease in mean score.",
    "The model explains approximately 66.25% of the variance in the mean score for all students in the dataset."
  )
)

kable(interpretations_df, format = "markdown", caption = "Interpretations of the Robust Regression Model Coefficients for Mississippi")
```

------------------------------------------------------------------------

We describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You'll also reflect on next steps and further analysis.

The audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.

While the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.

The style of this paper should aim to be that of an academic paper. I don't expect this to be of publication quality but you should keep that aim in mind. Avoid using "we" too frequently, for example "We also found that ...". Describe your methodology and your findings but don't describe your whole process.

## Rubric: On this page

You will

-   Introduce what motivates your Data Analysis (DA)
    -   Which variables and relationships are you most interested in?
    -   What questions are you interested in answering?
    -   Provide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.
-   Modeling and Inference
    -   The page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.
    -   Explain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)
    -   Describe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.
-   Explain the flaws and limitations of your analysis
    -   Are there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?
-   Clarity Figures
    -   Are your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?
    -   Each figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)
    -   Default `lm` output and plots are typically not acceptable.
-   Clarity of Explanations
    -   How well do you explain each figure/result?
    -   Do you provide interpretations that suggest further analysis or explanations for observed phenomenon?
-   Organization and cleanliness.
    -   Make sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.
    -   This page should be self-contained, i.e. provide a description of the relevant data.
