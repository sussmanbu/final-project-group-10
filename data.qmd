---
title: Data
description: We describe the sources of our data and the cleaning process.
toc: true
draft: false
---

![](images/data-import-cheatsheet-thumbs.png)



For larger datasets, you'll need to create a new folder in the project root directory named `dataset-ignore`. This will be ignored by git (based off the `.gitignore` file in the project root directory) which will help you avoid issues with Github's size limits. Your team will have to manually make sure the data files in `dataset-ignore` are synced across team members.

Your [load_and_clean_data.R](/scripts/load_and_clean_data.R) file is how you will load and clean your data. Here is a an example of a very simple one.


source(
  "scripts/load_and_clean_data.R",
  echo = TRUE # Use echo=FALSE or omit it to avoid code output  
)

You should never use absolute paths (eg. `/Users/danielsussman/path/to/project/` or `C:\MA415\\Final_Project\`).

You might consider using the `here` function from the [`here` package](https://here.r-lib.org/articles/here.html) to avoid path problems.

----

## Rubric: On this page

You will

* Describe where/how to find data.
  * You must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.
  * Why was the data collected/curated? Who put it together? (This is important, if you don't know why it was collected then that might not be a good dataset to look at.
* Describe the different data files used and what each variable means. 
  * If you have many variables then only describe the most relevant ones and summarize the rest.
* Describe any cleaning you had to do for your data.
  * You *must* include a link to your `load_and_clean_data.R` file.
  * Rrename variables and recode factors to make data more clear.
  * Also, describe any additional R packages you used outside of those covered in class.
  * Describe and show code for how you combined multiple data files and any cleaning that was necessary for that.
  * Some repetition of what you do in your `load_and_clean_data.R` file is fine and encouraged if it helps explain what you did.
* Organization, clarity, cleanliness of the page
  * Make sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.
  * This page should be self-contained.
  
----
  
## Our Data

Our data comes from the Stanford Education Data Archive, SEDA. Researchers at the Stanford Graduate School of Education conducted this project. SEDA provides comprehensive, publicly available data on U.S. K-12 education. 

The data is primarily gathered for academic research, policy analysis, and accountability purposes. Researchers utilize it to study educational disparities, policy effectiveness, and the impact of various interventions. Policymakers rely on this data to make informed decisions, allocate resources, and hold stakeholders accountable for student outcomes.

Link to the original data source: https://edopportunity.org/get-the-data/seda-archive-downloads/


SEDA data has been instrumental in education policy and economics research, providing crucial insights into the educational impacts of COVID-19 through studies such as “The First Year of Pandemic Recovery: A District-Level Analysis” and “School District and Community Factors Associated With Learning Loss During the COVID-19 Pandemic”. These investigations delve into the significant shifts to remote learning and the associated declines in math and reading achievements, offering a district-level perspective on the pandemic’s profound effects on education. Moreover, by examining data from 7,800 districts, the research explores how income levels, minority status, and the extent of remote instruction have influenced learning losses, shedding light on the complex interplay of external factors affecting educational outcomes during this unprecedented time.
----

### Variables and Files



[cleaning script](/scripts/load_and_clean_data.R)